{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Classify Quranic Chapters as 'Meccan' or 'Medinan'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore whether it is possible to build a binary classifier for surahs based on the words used in their verses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "verses = pd.read_csv(\"data/verses.txt\", header=0, delimiter=\"|\", quoting=3, encoding='utf-8')\n",
    "labels = np.genfromtxt(\"data/surah-labels.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Bag-Of-Words Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step can take up to a minute or so to run. It can be optimized but its not necessary for a fixed corpus, like the text of the Quran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Quran has 78245  words.\n",
      "The Quran has 14870 unique words, allowing for vowel variations.\n",
      "The Quran has approximately 4613  Meccan verses.\n",
      "The Quran has approximately 1623  Medinan verses.\n",
      "This is approximate because some Meccan surahs include Medinan verses and vice versa\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "n_verses = verses.shape[0]\n",
    "word_bag = list()\n",
    "valid_verse_counter = 0\n",
    "\n",
    "for verse in range(n_verses):\n",
    "    if type(verses[\"Text\"][verse]) is str:\n",
    "        valid_verse_counter += 1\n",
    "        for word in verses[\"Text\"][verse].split(\" \"):\n",
    "            word_bag.append(word)\n",
    "            \n",
    "print(\"The Quran has\",len(word_bag),\" words.\")\n",
    "word_bag = list(set(word_bag))\n",
    "print(\"The Quran has\",len(word_bag),\"unique words, allowing for vowel variations.\")\n",
    "\n",
    "word_vectors = np.zeros(shape=[valid_verse_counter,len(word_bag)])\n",
    "verse_labels = np.zeros(shape=[valid_verse_counter])-1\n",
    "verse_chapter_mapping = np.zeros(shape=[valid_verse_counter]) \n",
    "\n",
    "valid_verse_counter = 0\n",
    "\n",
    "for verse in range(n_verses):\n",
    "    if type(verses[\"Text\"][verse]) is str:\n",
    "        for word in verses[\"Text\"][verse].split(\" \"):\n",
    "            index = word_bag.index(word)\n",
    "            word_vectors[valid_verse_counter,index] += 1\n",
    "        #apply labels to individual verses\n",
    "        ch_number = int(verses[\"Chapter\"][verse])\n",
    "        verse_labels[valid_verse_counter] = labels[ch_number-1,1] #-1 for 0-indexed np array\n",
    "        #create a mapping between verses and chapters\n",
    "        verse_chapter_mapping[valid_verse_counter] = ch_number\n",
    "\n",
    "        valid_verse_counter += 1\n",
    "        \n",
    "print(\"The Quran has approximately\",np.count_nonzero(verse_labels),\" Meccan verses.\")\n",
    "word_bag = list(set(word_bag))\n",
    "print(\"The Quran has approximately\",len(verse_labels)-np.count_nonzero(verse_labels),\" Medinan verses.\")\n",
    "print(\"This is approximate because some Meccan surahs include Medinan verses and vice versa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has: 2357 verses\n",
      "The validation set has: 3879 verses\n"
     ]
    }
   ],
   "source": [
    "#split based on surah level (to preserve independence between training and validation set)\n",
    "def partition(features, labels, verse_chapter_mapping, train_fraction=0.4):\n",
    "    n_chapters = int(np.max(verse_chapter_mapping))\n",
    "    n_train = int(train_fraction*n_chapters)\n",
    "    n_valid = n_chapters - n_train\n",
    "    \n",
    "    chapters = np.random.permutation(n_chapters) + 1 #zero-indexed np array\n",
    "    train_chapters, valid_chapters = chapters[:n_train], chapters[n_train:]\n",
    "    \n",
    "    train_indices = np.where(np.in1d(verse_chapter_mapping,train_chapters))[0]\n",
    "    valid_indices = np.where(np.in1d(verse_chapter_mapping,valid_chapters))[0]\n",
    "    \n",
    "    features_train = features[train_indices]\n",
    "    labels_train = labels[train_indices]\n",
    "    features_valid = features[valid_indices]\n",
    "    labels_valid = labels[valid_indices]\n",
    "    \n",
    "    return (features_train, labels_train, features_valid, labels_valid)\n",
    "\n",
    "features_train, labels_train, features_valid, labels_valid = partition(word_vectors, verse_labels, verse_chapter_mapping)\n",
    "print(\"The training set has:\",len(labels_train),\"verses\")\n",
    "print(\"The validation set has:\",len(labels_valid),\"verses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model = model.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verse Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We achieve 98.68% accuracy on the training set\n",
      "We achieve 86.26% accuracy on the validation set\n"
     ]
    }
   ],
   "source": [
    "# check the accuracy on the training set\n",
    "print('We achieve', str(round(100*model.score(features_train, labels_train), 2))+'% accuracy on the training set')\n",
    "print('We achieve', str(round(100*model.score(features_valid, labels_valid), 2))+'% accuracy on the validation set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the large number of features, its not surprising that there is some overfitting happening. However, our results on the validation set do suggest that the classifier is learning something. How much better is this than chance? Well, we started with an unbalanced dataset, so if our classifier was just classifying every verse as Meccan, it would get an accuracy of about 74%. Depending on the specific partitioning of the training and validation, this is around 10 percentage points higher than that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surah Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see how well the classifier can predict an entire *surah* is Meccan or Medinan. This is also more fair since many Meccan surahs include Medinan verses and vice versa, which we don't take into accout when training or measuring the performance of our results.\n",
    "\n",
    "We will simply use majority voting to decide if a surah is Meccan or Medinan. If a majority of a surahs' verses are Meccan, the entire surah will be Meccan and same for Medinan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surahs It Misclassified as Meccan:\n",
      "---------------\n",
      "13  -- % Verses: 81.0\n",
      "22  -- % Verses: 63.0\n",
      "47  -- % Verses: 53.0\n",
      "55  -- % Verses: 100.0\n",
      "76  -- % Verses: 97.0\n",
      "99  -- % Verses: 100.0\n",
      "\n",
      "Surahs It Misclassified as Medinan:\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "chapter_predictions = np.zeros(shape=[int(np.max(verse_chapter_mapping)), 2])-1\n",
    "for chapter in range(1,int(np.max(verse_chapter_mapping))+1):\n",
    "    #get all the verse of that chapter\n",
    "    verses = np.where(verse_chapter_mapping==chapter)[0]\n",
    "    verse_predictions = model.predict(word_vectors[verses])\n",
    "    #see what majority of voters say\n",
    "    chapter_pred = np.round(np.mean(verse_predictions))\n",
    "    chapter_conf = np.mean(verse_predictions)\n",
    "    chapter_predictions[chapter-1, 0] = chapter_pred\n",
    "    chapter_predictions[chapter-1, 1] = round(100*(0.5+abs(0.5-chapter_conf)) \n",
    "    \n",
    "#compare to actual chapter labels\n",
    "pred_errors = chapter_predictions[:,0] - labels[:,1]\n",
    "print(\"Surahs It Misclassified as Meccan:\")\n",
    "print(\"---------------\")\n",
    "for i in np.where(pred_errors>0)[0]:\n",
    "    print(i+1, \" -- % Verses:\", str(chapter_predictions[i,1]))\n",
    "print(\"\\nSurahs It Misclassified as Medinan:\")\n",
    "print(\"---------------\")\n",
    "for i in np.where(pred_errors<0)[0]:\n",
    "    print(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further insight can be obtained by examining the weights in the logistic regression model. For example, we can see what words are most associated with a a Meccan surah, and what words are associated with a Medinan surah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Meccan Words\n",
      "------------------\n",
      "بعهدكم\n",
      "وتقسطوا\n",
      "العالمون\n",
      "أولاهما\n",
      "لتحصنكم\n",
      "العمى\n",
      "نور\n",
      "لمستقر\n",
      "لنفد\n",
      "تنزيل\n",
      "Top Medinan Words\n",
      "------------------\n",
      "تقتلني\n",
      "والله\n",
      "أكلها\n",
      "وإذ\n",
      "وبكفرهم\n",
      "مبصرة\n",
      "زلزلة\n",
      "بآية\n",
      "سخرناها\n",
      "وجهرا\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 10\n",
    "weights = model.coef_.flatten()\n",
    "\n",
    "idx = np.argpartition(weights, -TOP_N)[-TOP_N:]\n",
    "print(\"Top Meccan Words\\n------------------\")\n",
    "for i in idx:\n",
    "    print(word_bag[i])\n",
    "\n",
    "idx = np.argpartition(weights, TOP_N)[:TOP_N]\n",
    "print(\"Top Medinan Words\\n------------------\")\n",
    "for i in idx:\n",
    "    print(word_bag[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of this word is: 0.164471590085\n",
      "A very rough probability that the word is Meccan: 0.536413190447\n"
     ]
    }
   ],
   "source": [
    "def weight_of_word(word):\n",
    "    i = word_bag.index(word)\n",
    "    w = model.coef_.flatten()[i]\n",
    "    mx = max(abs(max(model.coef_.flatten())), abs(min(model.coef_.flatten())))\n",
    "    prob = (w + mx) / (2*mx)\n",
    "    print(\"The weight of this word is:\", w)\n",
    "    print(\"A very rough probability that the word is Meccan:\", prob)\n",
    "    \n",
    "weight_of_word(\"الشمس\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
